{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-10T06:20:17.030825900Z",
     "start_time": "2023-05-10T06:20:17.022825100Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from attention_seq2seq import AttentionSeq2seq\n",
    "from seq2seq import Seq2seq\n",
    "from peeky_seq2seq import PeekySeq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 读入数据\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T06:20:22.804087500Z",
     "start_time": "2023-05-10T06:20:22.417087Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 反转输入语句\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T06:20:27.167037400Z",
     "start_time": "2023-05-10T06:20:27.153037600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 设定超参数\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T06:20:32.416148900Z",
     "start_time": "2023-05-10T06:20:32.405151700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T06:20:39.090114300Z",
     "start_time": "2023-05-10T06:20:39.057113900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 4.08\n",
      "| epoch 1 |  iter 21 / 351 | time 6[s] | loss 3.09\n",
      "| epoch 1 |  iter 41 / 351 | time 12[s] | loss 1.90\n",
      "| epoch 1 |  iter 61 / 351 | time 18[s] | loss 1.72\n",
      "| epoch 1 |  iter 81 / 351 | time 24[s] | loss 1.46\n",
      "| epoch 1 |  iter 101 / 351 | time 30[s] | loss 1.19\n",
      "| epoch 1 |  iter 121 / 351 | time 36[s] | loss 1.14\n",
      "| epoch 1 |  iter 141 / 351 | time 42[s] | loss 1.09\n",
      "| epoch 1 |  iter 161 / 351 | time 48[s] | loss 1.06\n",
      "| epoch 1 |  iter 181 / 351 | time 54[s] | loss 1.04\n",
      "| epoch 1 |  iter 201 / 351 | time 60[s] | loss 1.03\n",
      "| epoch 1 |  iter 221 / 351 | time 66[s] | loss 1.02\n",
      "| epoch 1 |  iter 241 / 351 | time 72[s] | loss 1.02\n",
      "| epoch 1 |  iter 261 / 351 | time 78[s] | loss 1.01\n",
      "| epoch 1 |  iter 281 / 351 | time 84[s] | loss 1.00\n",
      "| epoch 1 |  iter 301 / 351 | time 91[s] | loss 1.00\n",
      "| epoch 1 |  iter 321 / 351 | time 97[s] | loss 1.00\n",
      "| epoch 1 |  iter 341 / 351 | time 103[s] | loss 1.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "X 1978-08-11\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "X 1978-08-11\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "X 1978-08-11\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "X 1978-08-11\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "X 1978-08-11\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "X 1978-08-11\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "X 1978-08-11\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "X 1978-08-11\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 1978-08-11\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "X 1978-08-11\n",
      "---\n",
      "val acc 0.000%\n",
      "| epoch 2 |  iter 1 / 351 | time 0[s] | loss 1.00\n",
      "| epoch 2 |  iter 21 / 351 | time 6[s] | loss 1.00\n",
      "| epoch 2 |  iter 41 / 351 | time 12[s] | loss 0.99\n",
      "| epoch 2 |  iter 61 / 351 | time 18[s] | loss 0.99\n",
      "| epoch 2 |  iter 81 / 351 | time 24[s] | loss 0.99\n",
      "| epoch 2 |  iter 101 / 351 | time 30[s] | loss 0.99\n",
      "| epoch 2 |  iter 121 / 351 | time 36[s] | loss 0.99\n",
      "| epoch 2 |  iter 141 / 351 | time 42[s] | loss 0.98\n",
      "| epoch 2 |  iter 161 / 351 | time 47[s] | loss 0.98\n",
      "| epoch 2 |  iter 181 / 351 | time 53[s] | loss 0.97\n",
      "| epoch 2 |  iter 201 / 351 | time 59[s] | loss 0.95\n",
      "| epoch 2 |  iter 221 / 351 | time 65[s] | loss 0.94\n",
      "| epoch 2 |  iter 241 / 351 | time 71[s] | loss 0.90\n",
      "| epoch 2 |  iter 261 / 351 | time 77[s] | loss 0.83\n",
      "| epoch 2 |  iter 281 / 351 | time 83[s] | loss 0.74\n",
      "| epoch 2 |  iter 301 / 351 | time 89[s] | loss 0.67\n",
      "| epoch 2 |  iter 321 / 351 | time 95[s] | loss 0.58\n",
      "| epoch 2 |  iter 341 / 351 | time 101[s] | loss 0.47\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "X 2006-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "X 2007-08-09\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "X 1983-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "X 2016-11-08\n",
      "---\n",
      "val acc 50.620%\n",
      "| epoch 3 |  iter 1 / 351 | time 0[s] | loss 0.35\n",
      "| epoch 3 |  iter 21 / 351 | time 6[s] | loss 0.30\n",
      "| epoch 3 |  iter 41 / 351 | time 12[s] | loss 0.21\n",
      "| epoch 3 |  iter 61 / 351 | time 18[s] | loss 0.14\n",
      "| epoch 3 |  iter 81 / 351 | time 24[s] | loss 0.09\n",
      "| epoch 3 |  iter 101 / 351 | time 30[s] | loss 0.07\n",
      "| epoch 3 |  iter 121 / 351 | time 36[s] | loss 0.05\n",
      "| epoch 3 |  iter 141 / 351 | time 42[s] | loss 0.04\n",
      "| epoch 3 |  iter 161 / 351 | time 48[s] | loss 0.03\n",
      "| epoch 3 |  iter 181 / 351 | time 54[s] | loss 0.03\n",
      "| epoch 3 |  iter 201 / 351 | time 60[s] | loss 0.02\n",
      "| epoch 3 |  iter 221 / 351 | time 66[s] | loss 0.02\n",
      "| epoch 3 |  iter 241 / 351 | time 72[s] | loss 0.02\n",
      "| epoch 3 |  iter 261 / 351 | time 78[s] | loss 0.01\n",
      "| epoch 3 |  iter 281 / 351 | time 84[s] | loss 0.01\n",
      "| epoch 3 |  iter 301 / 351 | time 90[s] | loss 0.01\n",
      "| epoch 3 |  iter 321 / 351 | time 96[s] | loss 0.01\n",
      "| epoch 3 |  iter 341 / 351 | time 102[s] | loss 0.01\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 99.900%\n",
      "| epoch 4 |  iter 1 / 351 | time 0[s] | loss 0.01\n",
      "| epoch 4 |  iter 21 / 351 | time 6[s] | loss 0.01\n",
      "| epoch 4 |  iter 41 / 351 | time 12[s] | loss 0.01\n",
      "| epoch 4 |  iter 61 / 351 | time 18[s] | loss 0.01\n",
      "| epoch 4 |  iter 81 / 351 | time 24[s] | loss 0.01\n",
      "| epoch 4 |  iter 101 / 351 | time 30[s] | loss 0.01\n",
      "| epoch 4 |  iter 121 / 351 | time 36[s] | loss 0.00\n",
      "| epoch 4 |  iter 141 / 351 | time 42[s] | loss 0.01\n",
      "| epoch 4 |  iter 161 / 351 | time 48[s] | loss 0.00\n",
      "| epoch 4 |  iter 181 / 351 | time 54[s] | loss 0.00\n",
      "| epoch 4 |  iter 201 / 351 | time 60[s] | loss 0.00\n",
      "| epoch 4 |  iter 221 / 351 | time 66[s] | loss 0.00\n",
      "| epoch 4 |  iter 241 / 351 | time 72[s] | loss 0.00\n",
      "| epoch 4 |  iter 261 / 351 | time 78[s] | loss 0.00\n",
      "| epoch 4 |  iter 281 / 351 | time 84[s] | loss 0.00\n",
      "| epoch 4 |  iter 301 / 351 | time 90[s] | loss 0.00\n",
      "| epoch 4 |  iter 321 / 351 | time 96[s] | loss 0.00\n",
      "| epoch 4 |  iter 341 / 351 | time 102[s] | loss 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 99.900%\n",
      "| epoch 5 |  iter 1 / 351 | time 0[s] | loss 0.00\n",
      "| epoch 5 |  iter 21 / 351 | time 6[s] | loss 0.00\n",
      "| epoch 5 |  iter 41 / 351 | time 12[s] | loss 0.00\n",
      "| epoch 5 |  iter 61 / 351 | time 18[s] | loss 0.00\n",
      "| epoch 5 |  iter 81 / 351 | time 24[s] | loss 0.00\n",
      "| epoch 5 |  iter 101 / 351 | time 30[s] | loss 0.00\n",
      "| epoch 5 |  iter 121 / 351 | time 36[s] | loss 0.00\n",
      "| epoch 5 |  iter 141 / 351 | time 42[s] | loss 0.00\n",
      "| epoch 5 |  iter 161 / 351 | time 48[s] | loss 0.00\n",
      "| epoch 5 |  iter 181 / 351 | time 54[s] | loss 0.00\n",
      "| epoch 5 |  iter 201 / 351 | time 60[s] | loss 0.00\n",
      "| epoch 5 |  iter 221 / 351 | time 66[s] | loss 0.00\n",
      "| epoch 5 |  iter 241 / 351 | time 72[s] | loss 0.00\n",
      "| epoch 5 |  iter 261 / 351 | time 78[s] | loss 0.00\n",
      "| epoch 5 |  iter 281 / 351 | time 84[s] | loss 0.00\n",
      "| epoch 5 |  iter 301 / 351 | time 90[s] | loss 0.00\n",
      "| epoch 5 |  iter 321 / 351 | time 97[s] | loss 0.00\n",
      "| epoch 5 |  iter 341 / 351 | time 103[s] | loss 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 99.920%\n",
      "| epoch 6 |  iter 1 / 351 | time 0[s] | loss 0.00\n",
      "| epoch 6 |  iter 21 / 351 | time 6[s] | loss 0.00\n",
      "| epoch 6 |  iter 41 / 351 | time 12[s] | loss 0.00\n",
      "| epoch 6 |  iter 61 / 351 | time 18[s] | loss 0.00\n",
      "| epoch 6 |  iter 81 / 351 | time 24[s] | loss 0.00\n",
      "| epoch 6 |  iter 101 / 351 | time 30[s] | loss 0.00\n",
      "| epoch 6 |  iter 121 / 351 | time 36[s] | loss 0.00\n",
      "| epoch 6 |  iter 141 / 351 | time 43[s] | loss 0.00\n",
      "| epoch 6 |  iter 161 / 351 | time 49[s] | loss 0.00\n",
      "| epoch 6 |  iter 181 / 351 | time 55[s] | loss 0.00\n",
      "| epoch 6 |  iter 201 / 351 | time 61[s] | loss 0.00\n",
      "| epoch 6 |  iter 221 / 351 | time 67[s] | loss 0.00\n",
      "| epoch 6 |  iter 241 / 351 | time 73[s] | loss 0.00\n",
      "| epoch 6 |  iter 261 / 351 | time 79[s] | loss 0.00\n",
      "| epoch 6 |  iter 281 / 351 | time 85[s] | loss 0.00\n",
      "| epoch 6 |  iter 301 / 351 | time 91[s] | loss 0.00\n",
      "| epoch 6 |  iter 321 / 351 | time 97[s] | loss 0.00\n",
      "| epoch 6 |  iter 341 / 351 | time 103[s] | loss 0.01\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "O 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "O 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "O 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "O 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "O 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "O 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "O 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "O 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "O 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "O 2016-11-06\n",
      "---\n",
      "val acc 96.140%\n",
      "| epoch 7 |  iter 1 / 351 | time 0[s] | loss 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m acc_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_epoch):\n\u001B[1;32m----> 3\u001B[0m     \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_grad\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     correct_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(x_test)):\n",
      "File \u001B[1;32mD:\\python2\\code7\\NLP\\01_深度学习进阶：自然语言处理\\8_Attention\\..\\common\\trainer.py:40\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# 计算梯度，更新参数\u001B[39;00m\n\u001B[0;32m     39\u001B[0m loss \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mforward(batch_x, batch_t)\n\u001B[1;32m---> 40\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m params, grads \u001B[38;5;241m=\u001B[39m remove_duplicate(model\u001B[38;5;241m.\u001B[39mparams, model\u001B[38;5;241m.\u001B[39mgrads)  \u001B[38;5;66;03m# 将共享的权重整合为1个\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m max_grad \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\python2\\code7\\NLP\\01_深度学习进阶：自然语言处理\\8_Attention\\seq2seq.py:113\u001B[0m, in \u001B[0;36mSeq2seq.backward\u001B[1;34m(self, dout)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward\u001B[39m(\u001B[38;5;28mself\u001B[39m, dout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m    112\u001B[0m     dout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msoftmax\u001B[38;5;241m.\u001B[39mbackward(dout)\n\u001B[1;32m--> 113\u001B[0m     dh \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m     dout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder\u001B[38;5;241m.\u001B[39mbackward(dh)\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dout\n",
      "File \u001B[1;32mD:\\python2\\code7\\NLP\\01_深度学习进阶：自然语言处理\\8_Attention\\attention_seq2seq.py:62\u001B[0m, in \u001B[0;36mAttentionDecoder.backward\u001B[1;34m(self, dscore)\u001B[0m\n\u001B[0;32m     59\u001B[0m H \u001B[38;5;241m=\u001B[39m H2 \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     61\u001B[0m dc, ddec_hs0 \u001B[38;5;241m=\u001B[39m dout[:,:,:H], dout[:,:,H:]\n\u001B[1;32m---> 62\u001B[0m denc_hs, ddec_hs1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m ddec_hs \u001B[38;5;241m=\u001B[39m ddec_hs0 \u001B[38;5;241m+\u001B[39m ddec_hs1\n\u001B[0;32m     64\u001B[0m dout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlstm\u001B[38;5;241m.\u001B[39mbackward(ddec_hs)\n",
      "File \u001B[1;32mD:\\python2\\code7\\NLP\\01_深度学习进阶：自然语言处理\\8_Attention\\attention_layer.py:111\u001B[0m, in \u001B[0;36mTimeAttention.backward\u001B[1;34m(self, dout)\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(T):\n\u001B[0;32m    110\u001B[0m     layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[t]\n\u001B[1;32m--> 111\u001B[0m     dhs, dh \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdout\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    112\u001B[0m     dhs_enc \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m dhs\n\u001B[0;32m    113\u001B[0m     dhs_dec[:,t,:] \u001B[38;5;241m=\u001B[39m dh\n",
      "File \u001B[1;32mD:\\python2\\code7\\NLP\\01_深度学习进阶：自然语言处理\\8_Attention\\attention_layer.py:78\u001B[0m, in \u001B[0;36mAttention.backward\u001B[1;34m(self, dout)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward\u001B[39m(\u001B[38;5;28mself\u001B[39m, dout):\n\u001B[1;32m---> 78\u001B[0m     dhs0, da \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight_sum_layer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m     dhs1, dh \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention_weight_layer\u001B[38;5;241m.\u001B[39mbackward(da)\n\u001B[0;32m     80\u001B[0m     dhs \u001B[38;5;241m=\u001B[39m dhs0 \u001B[38;5;241m+\u001B[39m dhs1\n",
      "File \u001B[1;32mD:\\python2\\code7\\NLP\\01_深度学习进阶：自然语言处理\\8_Attention\\attention_layer.py:29\u001B[0m, in \u001B[0;36mWeightSum.backward\u001B[1;34m(self, dc)\u001B[0m\n\u001B[0;32m     27\u001B[0m dar \u001B[38;5;241m=\u001B[39m dt \u001B[38;5;241m*\u001B[39m hs\n\u001B[0;32m     28\u001B[0m dhs \u001B[38;5;241m=\u001B[39m dt \u001B[38;5;241m*\u001B[39m ar\n\u001B[1;32m---> 29\u001B[0m da \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dhs, da\n",
      "File \u001B[1;32m<__array_function__ internals>:5\u001B[0m, in \u001B[0;36msum\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\A\\envs\\fproject\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2259\u001B[0m, in \u001B[0;36msum\u001B[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m   2256\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m out\n\u001B[0;32m   2257\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\u001B[1;32m-> 2259\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapreduction\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2260\u001B[0m \u001B[43m                      \u001B[49m\u001B[43minitial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\A\\envs\\fproject\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001B[0m, in \u001B[0;36m_wrapreduction\u001B[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001B[0m\n\u001B[0;32m     83\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     84\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m reduction(axis\u001B[38;5;241m=\u001B[39maxis, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n\u001B[1;32m---> 86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ufunc\u001B[38;5;241m.\u001B[39mreduce(obj, axis, dtype, out, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse=True)\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('val acc %.3f%%' % (acc * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-10T06:41:45.378550500Z",
     "start_time": "2023-05-10T06:21:26.530287300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_params()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
